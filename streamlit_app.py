import streamlit as st
from streamlit_webrtc import webrtc_streamer
import deepface as DeepFace

# FunÃ§Ã£o para realizar o reconhecimento facial e detectar emoÃ§Ãµes
def detect_emotion(image):
    try:
        analysis = DeepFace.analyze(image, actions=['emotion'], enforce_detection=False)
        return analysis['dominant_emotion']
    except Exception as e:
        return "Erro no reconhecimento facial"

# TÃ­tulo
st.title("Qual Ã© o seu sentimento atual?")

# Inicializa a cÃ¢mera (ativa, mas nÃ£o exibida para o usuÃ¡rio)
webrtc_ctx = webrtc_streamer(key="key", video_processor_factory=None, media_stream_constraints={"video": True, "audio": False}, mode="recvonly", async_processing=True)

# ExibiÃ§Ã£o dos botÃµes de sentimentos com emojis
col1, col2, col3, col4, col5 = st.columns(5)
sentimento = None

if col1.button("ğŸ˜€"):
    sentimento = "feliz"
if col2.button("ğŸ˜„"):
    sentimento = "alegre"
if col3.button("ğŸ˜"):
    sentimento = "normal"
if col4.button("ğŸ˜•"):
    sentimento = "triste"
if col5.button("ğŸ˜¡"):
    sentimento = "raivoso"

# Se o sentimento for escolhido, captura a foto e faz a anÃ¡lise
if sentimento:
    
    # Verifica se a cÃ¢mera estÃ¡ ativa e captura o frame
    if webrtc_ctx and webrtc_ctx.video_receiver:
        frame = webrtc_ctx.video_receiver.get_frame()
        image = frame.to_ndarray(format="bgr24")

        # Processa a imagem e detecta o sentimento sem exibir a foto
        emotion = detect_emotion(image)
        st.write(f"O sentimento detectado pela anÃ¡lise facial Ã©: *{emotion}*")
    else:
        st.warning("Nenhuma cÃ¢meraÂ detectada.")

